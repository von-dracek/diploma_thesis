\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
Stochastic programming is a branch of mathematical optimization that allows to account for uncertain parameters when solving mathematical programs, which led to the widespread adoption of stochastic programming in fields such as finance, transportation, scheduling and telecommunications, see \cite{stochasticprogrammingbible2009}. 

This makes it a very powerful tool, which however comes at a significant computational cost. Due to the fact that the random parameters may follow a continuous distribution, approximating such distributions by a discrete set of scenarios is necessary to even be able to formulate the model and also to be able to solve it in finite time. Even more demanding are so called multistage programs, which allow multiple decision periods. To be able to solve multistage programs, the scenarios approximating the continuous distributions in every stage are arranged in a scenario tree. The structure of this tree is very important for the obtained solution, as a tree that is very simple may not approximate the underlying distribution correctly, while a tree that is too complex suffers from extensive computational costs. 

This is the main idea of this thesis -- to discover whether it is possible to predict a scenario tree structure that is optimal with regard to the objective function and also potentially with regard to the complexity of the scenario tree. To solve this problem, we propose an experiment to train a reinforcement learning agent (we follow mainly \cite{sutton2018reinforcement}) using the solutions of a mean-CVaR model (defined for example in \cite{cvar_robust_mean_cvar_portfolio_optimization}) calculated using scenario trees generated from historical financial data. 

Chapters \ref{chap1}, \ref{chap2} and \ref{chapter3} provide the necessary theory for Multistage stochastic programming, the mean-CVaR model and Reinforcement learning respectively. The mean CVaR model formulated in Section \ref{section:endofhorizoncvar_scenario_formulation}, while certainly not novel, is of our own design.  The main contribution of this thesis is Chapter \ref{chapter4}, the pinnacle of this thesis, where we implement the experiment described above and analyse the results. To the best of our knowledge, such an experiment has not been proposed in the literature. Also a notable contribution is the compilation and standardization of notation for several machine learning algorithms in Chapter \ref{chapter3} from multiple different sources.