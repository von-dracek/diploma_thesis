\chapter{Stochastic programming}


%
%Structure of thesis:
%Introduction
%Multistage stochastic programming problems
%-multistage idea, nonanticipativity constraints, deterministic equivalent
%-curse of dimensionality
%-scenario trees 
%    -moment matching, geometric brownian motion + clustering
%Risk measures
%-VaR, CVaR, minimisation, L shaped method, reformulating as a multistage program
%Reinforcement learning
%-introduction, comparison to other types (supervised etc), no loss function - inspiration from learning of animals and men
%-Basic idea
%-Multiarmed bandits
%Study
%-Formulation of the whole problem (idea of thesis)
%    -Idea how to evaluate
%    -Penalisation of result using complexity of tree with a hyperparameter - explain reasoning why we should penalise the result - why are complex scenario trees bad (long computation time, ...)?
%-Data
%-Computational problems, complexity, how long does solving each small problem take
%-Results of the study
%

%Stochastic programming 
%-Framework to model problems which involve uncertainty
%-Optimization problem where some or all parameters are uncertain in contrast to deterministic optimization
%-the goal is to find a solution which is feasible for all such data and optimal in some sense
%-Stochastic programming models are similar in style but take advantage of the fact that probability distributions governing the data are known or can be estimated
%-The goal is to find some policy that is feasible for all (or almost all) the possible parameter realizations
%and optimizes the expectation of some function of the decisions and the random variables
%-Areas where stochastic programming is used
%	-financial planning, airline scheduling, transportation (truck routes, daily milk delivery with random demand), management of power systems
	
In this chapter, we give an introduction to the theory of stochastic programming with particular focus on multistage linear programs. Most of the content in this chapter is based on the material covered in \cite[Chapter 1]{stochasticprogrammingbible}, \cite[Chapters 1-3]{stochasticprogrammingbible2009} and \cite[Part 2]{dupacovastochasticprogramming}.
\todo{Add more meat here}

\section{Basic definitions}
\begin{defn}{Mathematical program in $\R^n$ \cite[p. 107]{dupacovastochasticprogramming}}. \\
\label{def:MathematicalProgramDef}
Let $p,m,n \in \N$. A mathematical program in $\R^n$ is defined as
\begin{equation*}
\mathrm{min} \{f(\mathbf{x}), \mathbf{x} \in \mathbf{M}\},
\end{equation*}
where $\mathbf{M} \subset \R^n$ and $f$ is a real function. The function $f$ is called the objective function and the set $\mathbf{M}$ is called the set of feasible solutions. 
This set is usually defined by constraints as follows:
\begin{equation*}
	\mathbf{M} = \{\mathbf{x} \in \R^n: h_j(\mathbf{x})=0, \, j=1,\dots,p, \, g_k(\mathbf{x}) \leq 0, k=1,\dots,m \},
\end{equation*}
where $h_j,j=1,\dots,p$ and $g_k, k=1,\dots,m $ are real functions.
\end{defn}
If $\mathbf{M}=\R^n$ and all functions in Definition~\ref{def:MathematicalProgramDef} are linear, we call the problem a \textit{Linear program}.
Furthermore, if any of the functions mentioned in Definition~\ref{def:MathematicalProgramDef} depend on parameters, we call the problem a \textit{Parametric program}. If any of the parameters are uncertain \textcolor{red}{(random variables)}\todo{Is random variable ok here? I assume it is, just for check.}, we call the problem a \textit{Stochastic program}.


However, the Stochastic program is not well defined. Consider the Definition~\ref{def:MathematicalProgramDef} and let $\Omega$ be a non-empty set, $\mathcal{F}$ be a  $\sigma$-algebra on $\Omega$, $\omega \in \Omega$ and $\mathcal{P}$ be a probability measure on $(\Omega, \mathcal{F})$, leading to a probability space $(\Omega, \mathcal{F}, \mathcal{P})$. In the context of a Stochastic program, the function $f$ does not depend on $\mathbf{x}$ only, but also on the realisation of $\omega$. This leads to a nonsensical definition, as for different realisations of $\omega$, the optimal value may be different. The standard way to handle this problem is to consider minimisation of expected value of the function $f$:

\begin{equation*}
\mathrm{min} \{\mathbb{E}\left[f(\mathbf{x}, \omega)\right], \mathbf{x} \in \mathbf{M}\},
\end{equation*}
where $\mathbb{E}$ is the expected value operator defined with respect to the probability measure $\mathcal{P}$. \todo{Are these definitions (mostly the probability measure stuff) correct?}


\section{Multistage stochastic programming}
The stochastic programming paradigm allows to make an optimal decision with regard to the expectation, but only for one decision period. This is a considerable limitation, which can be overcome by extending the notion of a \textit{Stochastic program} to a \textit{Multistage stochastic program}. 

\subsection{Notation and general idea}
This section is heavily inspired by \cite[Section 3.3.]{stochasticprogrammingbible}.
Following the notation established there, consider the following sequence of events
\begin{equation*}
\begin{gathered}
\mathrm{Decision} \, \, x_1 
\\
\downarrow
\\
\mathrm{Observation} \,\, \xi_2
\\
\downarrow
\\
\mathrm{Decision} \,\, x_2 
\\
\downarrow
\\
\mathrm{Observation} \,\, \xi_3
\\
\downarrow
\\
\vdots
\\
\downarrow
\\
\mathrm{Observation} \,\, \xi_T
\\
\downarrow
\\
\mathrm{Decision} \,\, x_T,
\end{gathered}
\end{equation*}
where $T$ is the number of stages, $x=(x_1,\dots,x_T)$ is called the decision process ($x_1$ is a non-random vector of variables), $\xi = (\xi_2,\dots,\xi_T)$ is a stochastic data process ($\xi_1$ is assumed to be known and deterministic). The decision process $x$ represents the decisions made at each stage (i.e. for a portfolio allocation problem, $x_t$ may be a random vector of proportions of some assets in a portfolio at some intermediate stage\todo{is this clear? Maybe rewrite}) and $\xi_T$ is a random vector representing the data proccess in the last stage (i.e. it may be a vector of yearly asset returns). Furthermore, the probability distribution of $\xi$ is assumed to be known.
\subsection{Nonanticipativity constraints}
Both processes $x$ and $\xi$ are random and thus depend on the realised $\omega \in \Omega$. In order for the program to be well defined, the decision process $x$ must not take into account future observations of either 
$\xi$ or decisions $x$, but only the past and present. This is formalised by the so called nonanticipativity constraints, which assure that the $x_t$ may depend only on $(x_1,\dots,x_{t-1})$ and $(\xi_1,...,\xi_{t})$.

\begin{defn}{Nonanticipativity constraints} \cite[Section 3.3.]{stochasticprogrammingbible}. \\
\label{def:nonanticipativity constraints}
The decision process $x$ is termed nonanticipative if
\begin{equation*}
x_t=\mathbb{E}\left[x_t|\xi_1,\dots,\xi_t \right], t=1,\dots,T,
\end{equation*}
or equivalently, if $\mathcal{F}_t$ is the $\sigma$-algebra generated by $(\xi_1,\dots,\xi_t)$, then $x_t(\omega)$\todo{should ($\omega$) be here?} must be measurable with respect to $\mathcal{F}_t$, where $\mathcal{F}_1 \subset \mathcal{F}_2 \subset \dots \subset \mathcal{F}_T \subset \mathcal{F}$.
\end{defn}

\subsection{Scenario trees}
\subsubsection{Methods for generation of scenario trees}
\subsection{Curse of dimensionality}
\section{Risk measures}
